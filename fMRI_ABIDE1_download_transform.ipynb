{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and transform the fMRI data for the ABIDE1 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn as nl\n",
    "from nilearn import datasets\n",
    "from nilearn import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xavier\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\numpy\\lib\\npyio.py:2278: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  output = genfromtxt(fname, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['description', 'phenotypic', 'func_preproc'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd_fmri = nl.datasets.fetch_abide_pcp(data_dir='E:\\ASD_cpac',  pipeline='cpac')\n",
    "\n",
    "asd_fmri.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:\\\\ASD_cpac\\\\ABIDE_pcp\\\\cpac\\\\nofilt_noglobal\\\\Pitt_0050003_func_preproc.nii.gz', 'E:\\\\ASD_cpac\\\\ABIDE_pcp\\\\cpac\\\\nofilt_noglobal\\\\Pitt_0050004_func_preproc.nii.gz', 'E:\\\\ASD_cpac\\\\ABIDE_pcp\\\\cpac\\\\nofilt_noglobal\\\\Pitt_0050005_func_preproc.nii.gz', 'E:\\\\ASD_cpac\\\\ABIDE_pcp\\\\cpac\\\\nofilt_noglobal\\\\Pitt_0050006_func_preproc.nii.gz', 'E:\\\\ASD_cpac\\\\ABIDE_pcp\\\\cpac\\\\nofilt_noglobal\\\\Pitt_0050007_func_preproc.nii.gz', 'E:\\\\ASD_cpac\\\\ABIDE_pcp\\\\cpac\\\\nofilt_noglobal\\\\Pitt_0050008_func_preproc.nii.gz', 'E:\\\\ASD_cpac\\\\ABIDE_pcp\\\\cpac\\\\nofilt_noglobal\\\\Pitt_0050010_func_preproc.nii.gz', 'E:\\\\ASD_cpac\\\\ABIDE_pcp\\\\cpac\\\\nofilt_noglobal\\\\Pitt_0050011_func_preproc.nii.gz', 'E:\\\\ASD_cpac\\\\ABIDE_pcp\\\\cpac\\\\nofilt_noglobal\\\\Pitt_0050012_func_preproc.nii.gz', 'E:\\\\ASD_cpac\\\\ABIDE_pcp\\\\cpac\\\\nofilt_noglobal\\\\Pitt_0050013_func_preproc.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "func_prep = asd_fmri.func_preproc\n",
    "print(func_prep[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note :\n",
    "Here I will create multiples datasets with several options, I don't know if I will use everything but since it takes forever to run I will try to capture the most of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# from nilearn.input_data import NiftiLabelsMasker\n",
    "# from nilearn import connectome\n",
    "\n",
    "# # prerequis \n",
    "# multiscale = datasets.fetch_atlas_basc_multiscale_2015(resume=True)\n",
    "# print('---------------------------------------------------------------------------------')\n",
    "# print()\n",
    "# print('Atlas ROIs are located at: %s' % multiscale.scale064)\n",
    "# print()\n",
    "# print('---------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "# label_masker = NiftiLabelsMasker(labels_img=multiscale.scale064, standardize=True)\n",
    "\n",
    "# correlation_measure = connectome.ConnectivityMeasure(kind='correlation', vectorize=True) # tangent kind across group\n",
    "\n",
    "# list_of_matrix = []\n",
    "\n",
    "# print('Transforming data into matrix...')\n",
    "# print()\n",
    "# # iterate through my files, transform them in to a flatten (half) matrix\n",
    "# for scan in tqdm(range(0, (len(asd_fmri.func_preproc)))):\n",
    "    \n",
    "#     if scan == 101:\n",
    "#         pass\n",
    "    \n",
    "#     else:\n",
    "#         # pathway \n",
    "#         fmri = func_prep[scan]\n",
    "\n",
    "#         # transfom into array\n",
    "#         fmri_matrix = label_masker.fit_transform(os.path.join(fmri))\n",
    "\n",
    "#         # transform into matrix \n",
    "#         correlation_matrix = correlation_measure.fit_transform([fmri_matrix])\n",
    "\n",
    "#         # append this matrix to the list\n",
    "#         list_of_matrix.append(correlation_matrix)\n",
    "\n",
    "# print()\n",
    "# print('Data transformed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datasets with the correlation/tangent matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/871 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Atlas ROIs are located at: C:\\Users\\xavier/nilearn_data\\basc_multiscale_2015\\template_cambridge_basc_multiscale_nii_sym\\template_cambridge_basc_multiscale_sym_scale064.nii.gz\n",
      "\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 871/871 [1:51:58<00:00,  7.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time series created.\n",
      "\n",
      "Data has 403 ASD.\n",
      "Data has 467 Control.\n",
      "Data has 870 subjects.\n"
     ]
    }
   ],
   "source": [
    "import nilearn as nl\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all user warnings\n",
    "simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "# prerequis \n",
    "multiscale = datasets.fetch_atlas_basc_multiscale_2015(resume=True)\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print()\n",
    "print('Atlas ROIs are located at: %s' % multiscale.scale064)\n",
    "print()\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "ASD = []\n",
    "control = []\n",
    "all_subjects = []\n",
    "\n",
    "label_masker = NiftiLabelsMasker(labels_img=multiscale.scale064, standardize=True).fit()\n",
    "\n",
    "for subject in tqdm(range(len(func_prep))):\n",
    "    \n",
    "    if subject == 101:\n",
    "        pass \n",
    "    else: \n",
    "        time_serie = label_masker.transform(os.path.join(func_prep[subject]))\n",
    "        all_subjects.append(time_serie)\n",
    "        \n",
    "        if asd_fmri.phenotypic['DX_GROUP'][subject] == 1:\n",
    "            ASD.append(time_serie)\n",
    "        else:\n",
    "            control.append(time_serie)\n",
    "\n",
    "print()\n",
    "print('Time series created.')\n",
    "print()\n",
    "print('Data has {0} ASD.'.format(len(ASD)))\n",
    "print('Data has {0} Control.'.format(len(control)))\n",
    "print('Data has {0} subjects.'.format(len(all_subjects)))\n",
    "\n",
    "df_asd = pd.DataFrame(data={'ASD': ASD})\n",
    "df_asd.to_csv('asd_sub_bygroup_timeseries.csv', index=False, encoding='utf-8')\n",
    "df_c = pd.DataFrame(data={'Control': control})\n",
    "df_c.to_csv('control_sub_bygroup_timeseries.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation matrix / tangent matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the time series as well, might be usefull\n",
      "Target shape: (870,)\n",
      "Time serie shape: (870,)\n",
      "Npz file: train saved\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Pearson correlation\n",
      "Correlation matrix created\n",
      "Correlation matrix shape: (870, 2080)\n",
      "Npz file: train saved\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Tangent correlation\n",
      "Correlation matrix created\n",
      "Correlation matrix shape: (870, 2080)\n",
      "Npz file: train saved\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from nilearn import connectome\n",
    "\n",
    "print('Save the time series as well, might be usefull')\n",
    "\n",
    "df = pd.DataFrame(asd_fmri.phenotypic)\n",
    "# Drop the 101 rows \n",
    "df_new = df.drop([101], axis=0)\n",
    "# create the target\n",
    "target = df_new.DX_GROUP.values\n",
    "print('Target shape:', target.shape)\n",
    "\n",
    "time_series_array = np.asarray(all_subjects)\n",
    "print('Time serie shape:', time_series_array.shape)\n",
    "\n",
    "# Save into a npz \n",
    "np.savez('fMRI_time_series.npz', matrix=time_series_array, targets=target)\n",
    "\n",
    "print('Npz file: train saved')\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print()\n",
    "print('Pearson correlation')\n",
    "\n",
    "correlation_measure = connectome.ConnectivityMeasure(kind='correlation', vectorize=True)\n",
    "\n",
    "# Transform data into matrix \n",
    "matrices_correlation = correlation_measure.fit_transform(all_subjects)\n",
    "\n",
    "print('Correlation matrix created')\n",
    "print('Correlation matrix shape:', matrices_correlation.shape)\n",
    "\n",
    "\n",
    "# Save into a npz \n",
    "np.savez('fMRI_matrix.npz', matrix=matrices_correlation, targets=target)\n",
    "\n",
    "print('Npz file: train saved')\n",
    "\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print()\n",
    "print('Tangent correlation')\n",
    "\n",
    "tangent_measure = connectome.ConnectivityMeasure(kind='tangent', vectorize=True)\n",
    "\n",
    "# Transform data into matrix \n",
    "matrices_tangent = tangent_measure.fit_transform(all_subjects)\n",
    "\n",
    "print('Correlation matrix created')\n",
    "print('Correlation matrix shape:', matrices_tangent.shape)\n",
    "\n",
    "# Save into a npz \n",
    "np.savez('fMRI_tangent_matrix.npz', matrix=matrices_tangent, targets=target)\n",
    "\n",
    "print('Npz file: train saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try the correlations AND the confounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/871 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Atlas ROIs are located at: C:\\Users\\xavier/nilearn_data\\basc_multiscale_2015\\template_cambridge_basc_multiscale_nii_sym\\template_cambridge_basc_multiscale_sym_scale064.nii.gz\n",
      "\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 871/871 [1:52:31<00:00,  7.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time series created.\n",
      "\n",
      "Data has 403 ASD.\n",
      "Data has 467 Control.\n",
      "Data has 870 subjects.\n"
     ]
    }
   ],
   "source": [
    "import nilearn as nl\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all user warnings\n",
    "simplefilter(action='ignore', category=UserWarning)\n",
    "from nilearn import image\n",
    "# A \"memory\" to avoid recomputation\n",
    "from nilearn._utils.compat import Memory\n",
    "mem = Memory('nilearn_cache')\n",
    "\n",
    "# prerequis \n",
    "multiscale = datasets.fetch_atlas_basc_multiscale_2015(resume=True)\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print()\n",
    "print('Atlas ROIs are located at: %s' % multiscale.scale064)\n",
    "print()\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "ASD_conf = []\n",
    "control_conf = []\n",
    "all_subjects_conf = []\n",
    "\n",
    "label_masker = NiftiLabelsMasker(labels_img=multiscale.scale064, standardize=True).fit()\n",
    "\n",
    "for subject in tqdm(range(len(func_prep))):\n",
    "    \n",
    "    if subject == 101:\n",
    "        pass \n",
    "    else: \n",
    "        hv_confounds = mem.cache(image.high_variance_confounds)(func_prep[subject]);\n",
    "        time_serie = label_masker.transform(os.path.join(func_prep[subject]), confounds=hv_confounds);\n",
    "        all_subjects_conf.append(time_serie)\n",
    "        \n",
    "        if asd_fmri.phenotypic['DX_GROUP'][subject] == 1:\n",
    "            ASD_conf.append(time_serie)\n",
    "        else:\n",
    "            control_conf.append(time_serie)\n",
    "\n",
    "print()\n",
    "print('Time series created.')\n",
    "print()\n",
    "print('Data has {0} ASD.'.format(len(ASD_conf)))\n",
    "print('Data has {0} Control.'.format(len(control_conf)))\n",
    "print('Data has {0} subjects.'.format(len(all_subjects_conf)))\n",
    "\n",
    "df_asd = pd.DataFrame(data={'ASD': ASD_conf})\n",
    "df_asd.to_csv('asd_sub_bygroup_timeseries_conf.csv', index=False, encoding='utf-8')\n",
    "df_c = pd.DataFrame(data={'Control': control_conf})\n",
    "df_c.to_csv('control_sub_bygroup_timeseries_conf.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation / tangent  matrix & confounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the time series as well, might be usefull\n",
      "Target shape: (870,)\n",
      "Time serie shape: (870,)\n",
      "Npz file: train saved\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Pearson correlation\n",
      "Correlation matrix created\n",
      "Correlation matrix shape: (870, 2080)\n",
      "Npz file: train saved\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Tangent correlation\n",
      "Correlation matrix created\n",
      "Correlation matrix shape: (870, 2080)\n",
      "Npz file: train saved\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from nilearn import connectome\n",
    "\n",
    "print('Save the time series as well, might be usefull')\n",
    "\n",
    "df = pd.DataFrame(asd_fmri.phenotypic)\n",
    "# Drop the 101 rows \n",
    "df_new = df.drop([101], axis=0)\n",
    "# create the target\n",
    "target = df_new.DX_GROUP.values\n",
    "print('Target shape:', target.shape)\n",
    "\n",
    "time_series_array = np.asarray(all_subjects_conf)\n",
    "print('Time serie shape:', time_series_array.shape)\n",
    "\n",
    "# Save into a npz \n",
    "np.savez('fMRI_time_series_confounds.npz', matrix=time_series_array, targets=target)\n",
    "\n",
    "print('Npz file: train saved')\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print()\n",
    "print('Pearson correlation')\n",
    "\n",
    "correlation_measure = connectome.ConnectivityMeasure(kind='correlation', vectorize=True)\n",
    "\n",
    "# Transform data into matrix \n",
    "matrices_correlation = correlation_measure.fit_transform(all_subjects_conf)\n",
    "\n",
    "print('Correlation matrix created')\n",
    "print('Correlation matrix shape:', matrices_correlation.shape)\n",
    "\n",
    "\n",
    "# Save into a npz \n",
    "np.savez('fMRI_matrix_confounds.npz', matrix=matrices_correlation, targets=target)\n",
    "\n",
    "print('Npz file: train saved')\n",
    "\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print()\n",
    "print('Tangent correlation')\n",
    "\n",
    "tangent_measure = connectome.ConnectivityMeasure(kind='tangent', vectorize=True)\n",
    "\n",
    "# Transform data into matrix \n",
    "matrices_tangent = tangent_measure.fit_transform(all_subjects_conf)\n",
    "\n",
    "print('Correlation matrix created')\n",
    "print('Correlation matrix shape:', matrices_tangent.shape)\n",
    "\n",
    "# Save into a npz \n",
    "np.savez('fMRI_tangent_matrix_confounds.npz', matrix=matrices_tangent, targets=target)\n",
    "\n",
    "print('Npz file: train saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
